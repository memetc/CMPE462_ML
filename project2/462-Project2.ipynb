{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>CMPE 462 - Project 2<br>Implementing an SVM Classifier<br>Due: May 18, 2020, 23:59</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Student ID1:** 2015400249\n",
    "* **Student ID2:** 2016400216\n",
    "* **Student ID3:** 2014400258"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this project, you are going to implement SVM. For this purpose, a data set (data.mat) is given to you. You can load the mat dataset into Python using the function `loadmat` in `Scipy.io`. When you load the data, you will obtain a dictionary object, where `X` stores the data matrix and `Y` stores the labels. You can use the first 150 samples for training and the rest for testing. In this project, you will use the software package [`LIBSVM`](http://www.csie.ntu.edu.tw/~cjlin/libsvm/) to implement SVM. Note that `LIBSVM` has a [`Python interface`](https://github.com/cjlin1/libsvm/tree/master/python), so you can call the SVM functions in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - 30 pts\n",
    "\n",
    "Train a hard margin linear SVM and report both train and test classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 13)\n",
      "(120, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from libsvm.svmutil import *\n",
    "from contextlib import contextmanager\n",
    "import sys, os\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "\n",
    "def calculateAccuracy(array1, array2):\n",
    "    correct_count = 0\n",
    "    size_data = len(array2)\n",
    "    for i in range(len(array1[0])):\n",
    "        val1 = array1[0][i]\n",
    "        val2 = array2[i][0]\n",
    "        #print(val1, val2 )\n",
    "        if  val1>0 and val2>0:\n",
    "            correct_count += 1\n",
    "                #print(\"correct\")\n",
    "        elif val1<0 and val2<0:\n",
    "            correct_count += 1\n",
    "                #print(\"correct\")\n",
    "        #else:\n",
    "            #print(\"not correct\")\n",
    "\n",
    "    accuracy = correct_count/size_data\n",
    "    print(\"Accuracy : \", accuracy)\n",
    "\n",
    "def countSV(array1, array2):\n",
    "    sv_count = 0\n",
    "    for i in range(len(array1[2])):\n",
    "        val = array1[2][i] * array2[i]\n",
    "        if val == 1:\n",
    "            sv_count += 1\n",
    "\n",
    "    print(\"sv count : \" , sv_count)\n",
    "\n",
    "\n",
    "data = sio.loadmat(\"data.mat\")\n",
    "data_x = np.array(data[\"X\"])\n",
    "data_y = np.array(data[\"Y\"])\n",
    "\n",
    "train_x = np.array(data_x[0:150,:])\n",
    "train_y = np.array(data_y[0:150,:])\n",
    "\n",
    "test_x = np.array(data_x[150:,:])\n",
    "test_y = np.array(data_y[150:,:])\n",
    "print(np.shape(test_x))\n",
    "print(np.shape(test_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.708333  1.        1.       ...  0.        1.       -1.      ]\n",
      " [ 0.583333 -1.        0.333333 ...  0.       -1.        1.      ]\n",
      " [ 0.166667  1.       -0.333333 ... -1.       -1.        1.      ]\n",
      " ...\n",
      " [-0.541667  1.        1.       ...  0.       -1.        1.      ]\n",
      " [ 0.208333  1.        0.333333 ... -1.        0.333333  1.      ]\n",
      " [-0.5      -1.        0.333333 ... -1.       -1.       -1.      ]]\n"
     ]
    }
   ],
   "source": [
    "#IMPLEMENT HARD MARGIN SVM\n",
    "\n",
    "#px = svm_problem(train_y.ravel(), train_x)\n",
    "\n",
    "print(train_x)\n",
    "prob = svm_problem(train_y.ravel(), train_x)\n",
    "m = svm_train(prob, '-t 0 -c 100000') #train with linear kernel and c = 100000\n",
    "\n",
    "with suppress_stdout():\n",
    "    train_prediction = svm_predict(train_y,train_x, m)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9\n",
      "Accuracy :  0.825\n"
     ]
    }
   ],
   "source": [
    "calculateAccuracy(train_prediction, train_y)\n",
    "\n",
    "size_test = len(test_y)\n",
    "with suppress_stdout():\n",
    "    test_prediction = svm_predict(test_y,test_x, m)\n",
    "\n",
    "\n",
    "calculateAccuracy(test_prediction, test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - 40 pts\n",
    "\n",
    "Train soft margin SVM for different values of the parameter $C$, and with different kernel functions. Systematically report your results. For instance, report the performances of different kernels for a fixed $C$, then report the performance for different $C$ values for a fixed kernel, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_soft = svm_problem(train_y.ravel(), train_x)\n",
    "m_soft_kernel1 = svm_train(prob_soft, '-t 0 -c 3') #train with linear kernel and c = 0\n",
    "m_soft_kernel2 = svm_train(prob_soft, '-t 3 -c 3') #train with linear kernel and c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8416666666666667\n",
      "Accuracy :  0.825\n"
     ]
    }
   ],
   "source": [
    "with suppress_stdout():\n",
    "    test_prediction_sm_kernel1 = svm_predict(test_y,test_x, m_soft_kernel1)\n",
    "    test_prediction_sm_kernel2 = svm_predict(test_y,test_x, m_soft_kernel2)\n",
    "    \n",
    "calculateAccuracy(test_prediction_sm_kernel1, test_y)\n",
    "calculateAccuracy(test_prediction_sm_kernel2, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_soft_c1 = svm_train(prob_soft, '-t 2 -c 1') #train with linear kernel and c = 0\n",
    "m_soft_c2 = svm_train(prob_soft, '-t 2 -c 100') #train with linear kernel and c = 0\n",
    "m_soft_c3 = svm_train(prob_soft, '-t 2 -c 1000') #train with linear kernel and c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8416666666666667\n",
      "Accuracy :  0.7833333333333333\n",
      "Accuracy :  0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "with suppress_stdout():\n",
    "    test_prediction_sm_c1 = svm_predict(test_y,test_x, m_soft_c1)\n",
    "    test_prediction_sm_c2 = svm_predict(test_y,test_x, m_soft_c2)\n",
    "    test_prediction_sm_c3 = svm_predict(test_y,test_x, m_soft_c3)\n",
    "\n",
    "calculateAccuracy(test_prediction_sm_c1, test_y)\n",
    "calculateAccuracy(test_prediction_sm_c2, test_y)\n",
    "calculateAccuracy(test_prediction_sm_c3, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - 15 pts\n",
    "\n",
    "Please report how the number of support vectors changes as the value of $C$ increases (while all other parameters remain the same). Discuss whether your observations match the theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83,)\n",
      "(70,)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "sv_c1 = m_soft_c1.get_SV()\n",
    "sv_c2 = m_soft_c2.get_SV()\n",
    "sv_c3 = m_soft_c3.get_SV()\n",
    "print(np.shape(sv_c1))\n",
    "print(np.shape(sv_c2))\n",
    "print(np.shape(sv_c3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - 15 pts\n",
    "\n",
    "Please investigate the changes in the hyperplane when you remove one of the support vectors, vs., one data point that is not a support vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.13365625  0.56672624  1.10960429  0.85136329  0.92456137  0.1672546\n",
      "  0.23397229 -1.12376604 -0.02407569 -0.29319709  0.36764449  2.81462132\n",
      "  0.46803858]\n",
      "1.8638659415742513\n",
      "[  50499.20498987  532426.00875612   43761.04746219  -16365.17700442\n",
      " -206856.98829529 -128091.66283821   24252.98596245 -220787.19225765\n",
      "  162850.38462649  198797.64097959  -79351.50416807 -107925.96496495\n",
      "  475223.71999137]\n",
      "1.701769970510478\n",
      "[ 107176.47024318   -1075.30318506  -13286.71191302  -24662.76586264\n",
      "   98475.27858452  -26401.6769624  -235249.86830264   44492.57364472\n",
      " -292805.35398981  -61798.22284671  -51815.63094628  126210.73220312\n",
      "  199539.09501501]\n",
      "2.379365035302916\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def findWeightsAndBias(sv, m, sv_coef):\n",
    "    sv_new = np.zeros((len(sv), 13))\n",
    "    for i in range(len(sv)):\n",
    "        temp = np.zeros([13,1])\n",
    "        for k,v in support_vectors[i].items():\n",
    "            if k != -1:\n",
    "                temp[k-1] = v\n",
    "        sv_new[i] = temp.ravel()\n",
    "    sv_new = np.transpose(sv_new) #convert sv_new to 13x49 matrix\n",
    "    w = (sv_new @ sv_coef); \n",
    "    rho = m.rho[0]\n",
    "    b = -rho\n",
    "    print(w) #weights\n",
    "    print(b) #bias\n",
    "    \n",
    "    \n",
    "support_vectors = m.get_SV()\n",
    "sv_coef = np.asarray(m.get_sv_coef()).ravel()\n",
    "sv_indices = np.asarray(m.get_sv_indices())\n",
    "#print(sv_indices) #index 3 is index 2 at train_x\n",
    "\n",
    "\n",
    "findWeightsAndBias(support_vectors, m, sv_coef) # print weights and bias without removing any data point\n",
    "\n",
    "\n",
    "train_x_without_sv = np.delete(train_x, 2, 0)\n",
    "train_y_without_sv = np.delete(train_y, 2, 0)\n",
    "prob1 = svm_problem(train_y_without_sv.ravel(), train_x_without_sv)\n",
    "m_without_sv = svm_train(prob1, '-t 0 -c 100000') #train with linear kernel and c = 100000\n",
    "sv1 = m_without_sv.get_SV()\n",
    "sv_coef1 = np.asarray(m_without_sv.get_sv_coef()).ravel()\n",
    "findWeightsAndBias(sv1, m_without_sv, sv_coef1) # print weights and bias after removing a sv\n",
    "    \n",
    "    \n",
    "train_x_without_datapoint = np.delete(train_x, 1, 0)\n",
    "train_y_without_datapoint = np.delete(train_y, 1, 0)\n",
    "prob2 = svm_problem(train_y_without_datapoint.ravel(), train_x_without_datapoint) \n",
    "m_without_nonsv = svm_train(prob2, '-t 0 -c 100000') #train with linear kernel and c = 100000\n",
    "sv2 = m_without_nonsv.get_SV()\n",
    "sv_coef2 = np.asarray(m_without_nonsv.get_sv_coef()).ravel()\n",
    "findWeightsAndBias(sv2, m_without_nonsv, sv_coef2) # print weights and bias after removing non sv data point\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Task - 10 pts\n",
    "\n",
    "Use Python and [CVXOPT](http://cvxopt.org) QP solver to implement the hard margin SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.2653e-01  1.9592e+00  6e+00  2e+00  4e+00\n",
      " 1:  1.5796e+00  8.5663e-01  7e-01  0e+00  2e-15\n",
      " 2:  1.0195e+00  9.9227e-01  3e-02  1e-16  1e-15\n",
      " 3:  1.0002e+00  9.9992e-01  3e-04  2e-16  2e-15\n",
      " 4:  1.0000e+00  1.0000e+00  3e-06  3e-16  7e-16\n",
      " 5:  1.0000e+00  1.0000e+00  3e-08  4e-16  7e-16\n",
      "Optimal solution found.\n",
      "[ 1.00e+00]\n",
      "[-1.00e+00]\n",
      "[ 1.00e+00]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cvxopt import matrix, solvers\n",
    "\n",
    "Q = matrix([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n",
    "p = matrix([0.0, 0.0, 0.0])\n",
    "A = matrix([[-1.0, -1.0, 1.0, 1.0], [0.0, -2.0, 2.0, 3.0], [0.0, -2.0, 0.0, 0.0]])\n",
    "c = matrix([-1.0, -1.0, -1.0, -1.0])\n",
    "sol=solvers.qp(Q,p,A,c)\n",
    "\n",
    "print(sol['x'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
